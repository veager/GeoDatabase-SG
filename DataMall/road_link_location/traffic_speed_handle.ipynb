{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dd7d3a-6f9a-4198-a734-37c2c115c8a1",
   "metadata": {},
   "source": [
    "**road traffic speed data:** Request from Datamall API: 2.14 ESTIMATED TRAVEL TIMES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b370d77f-3a9e-41aa-9eda-64824205637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a01bf7-cbe0-4be3-8c11-e5f0812314ef",
   "metadata": {},
   "source": [
    "# 1. Extract Road Link Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee4d11-fe00-448e-9417-a0432df89883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_road_loc(path):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "        path : TYPE\n",
    "            DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "        data : TYPE\n",
    "            DESCRIPTION.\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    path = '2022-06/2022-06-01/2022-06-01-00-49-27.csv' \n",
    "    data = read_road_loc(path)\n",
    "\n",
    "    '''\n",
    "    # initialization\n",
    "    if path is None:\n",
    "        data = pd.DataFrame(columns = ['LinkID', 'RoadName', 'RoadCategory', 'Location'], dtype=str)\n",
    "\n",
    "    # read data\n",
    "    try:\n",
    "        data = pd.read_csv(path, header=0, index_col=None, dtype=str)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    data.drop(['SpeedBand', 'MinimumSpeed', 'MaximumSpeed'], axis=1, inplace=True)\n",
    "    \n",
    "    # link location\n",
    "    data['Location'] = data['Location'].apply(lambda x: LineString([(float(x.split(' ')[1]), float(x.split(' ')[0])), \n",
    "                                                                    (float(x.split(' ')[3]), float(x.split(' ')[2]))]\n",
    "                                                                   ).wkt \n",
    "                                              )\n",
    "    # drop duplicate\n",
    "    try:\n",
    "        assert data['LinkID'].unique().shape[0] == data.shape[0]\n",
    "    except:\n",
    "        print(data['LinkID'].unique().shape[0], data.shape[0])\n",
    "        data.drop_duplicates(subset=['LinkID'], inplace=True)\n",
    "    \n",
    "    return data\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def extract_road_location(folder_path, save_path=None):\n",
    "    '''\n",
    "    read one month road traffic speed data, and extract the road location\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): DESCRIPTION.\n",
    "        save_path (str): DESCRIPTION.\n",
    "\n",
    "    Returns:\n",
    "        data_month_df (pandas.DataFrame): \n",
    "\n",
    "    '''\n",
    "    # initialization\n",
    "    data_month_df = read_road_loc(path=None)\n",
    "    \n",
    "    fd_day_li = os.listdir(folder_path)\n",
    "    \n",
    "    # for one day files\n",
    "    for fdn in fd_day_li:\n",
    "        fd_day_path = os.path.join(folder_path, fdn)\n",
    "        fn_data_li = os.listdir(fd_day_path)\n",
    "        \n",
    "        # for one sample data\n",
    "        for fn_data in fn_data_li:\n",
    "            \n",
    "            data_path = os.path.join(fd_day_path, fn_data)\n",
    "            data_new = read_road_loc(data_path)\n",
    "            if data_new is None:\n",
    "                continue\n",
    "            \n",
    "            data_month_df = pd.concat([data_month_df, data_new], axis=0, ignore_index=True)\n",
    "            data_month_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "        \n",
    "        # drop duplicate\n",
    "        try:\n",
    "            assert data_month_df['LinkID'].unique().shape[0] == data_month_df.shape[0]\n",
    "        except:\n",
    "            print(data_month_df['LinkID'].unique().shape[0], data_month_df.shape[0])\n",
    "            data.drop_duplicates(subset=['LinkID'], inplace=True)\n",
    "            \n",
    "        # since the above processing is time-cosuming, \n",
    "        # when one-day data is added, the file will be saved.\n",
    "        if not (save_path is None):\n",
    "            print('save: ', fdn, data_month_df.shape[0])\n",
    "            data_month_df.to_csv(save_path, index=False)\n",
    "    \n",
    "    return data_month_df\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41d335-54a7-4b75-b5cb-caeb91f7276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract from only one file\n",
    "path = '2022-06/2022-06-21/2022-06-21-23-16-33.csv' \n",
    "data = read_road_loc(path)\n",
    "data.to_csv('road_location_2022-06.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fff1b6-7cd7-44d0-b0e6-4254a9c81eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract from one-month file\n",
    "path = os.path.join(os.getcwd(), '2022-06')\n",
    "save_path = 'traffic_speed_data/road_location_2022-06.csv'\n",
    "\n",
    "data = extract_road_location(path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc58f90-4fb1-4485-aadb-e8df1b2619fa",
   "metadata": {},
   "source": [
    "# 2. Extract Monthly Average Traffic Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbe660-9ff6-4c06-834c-3ad7af19a920",
   "metadata": {},
   "source": [
    "## 2.1 Read function of one single file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a9231-8e95-4460-b3b3-77f1759f376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_traffic_speed(path):\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(path, header=0, index_col=None, dtype={'LinkID': str})\n",
    "    except:     # data is None\n",
    "        data = pd.DataFrame(columns = ['id', 'speed'], dtype = str)\n",
    "        return None\n",
    "    \n",
    "    data.dropna(axis=0, how='any', subset=['MinimumSpeed'], inplace=True)\n",
    "    \n",
    "    data = data.rename(columns = {'LinkID' : 'id'})\n",
    "    \n",
    "    data['speed'] = data['MinimumSpeed'] + 5\n",
    "    \n",
    "    data = data[['id', 'speed']]\n",
    "    data.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    # print(data['id'].value_counts())\n",
    "\n",
    "    try:\n",
    "        assert data['id'].unique().shape[0] == data.shape[0]\n",
    "    except:\n",
    "        print(data['id'].unique().shape[0], data.shape[0])\n",
    "        data.drop_duplicates(subset=['id'], inplace=True, ignore_index=True)\n",
    "    \n",
    "    return data\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5fea6-5b59-4359-aa4d-c94f3b39ba3a",
   "metadata": {},
   "source": [
    "### 2.2.1 Load one-month data\n",
    "\n",
    "- **Resample frequency:** 1 hour\n",
    "\n",
    "- **Resample method:** average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbd00f9-6bb6-4f6c-b624-aa520d9c7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_month_data(root_folder, data_value_name, save_path=None):\n",
    "    '''\n",
    "    '''\n",
    "    # one-month data\n",
    "    data_month_df = pd.DataFrame(columns=['id', data_value_name, 'datetime'])\n",
    "    data_month_df.to_csv(save_path, index=False, header=True)\n",
    "    \n",
    "    # one month data\n",
    "    for fd_day in os.listdir(root_folder):\n",
    "\n",
    "        fd_day_path = os.path.join(root_folder, fd_day)\n",
    "        fn_data_li = os.listdir(fd_day_path)\n",
    "\n",
    "        # one day data\n",
    "        data_day_df = pd.DataFrame(columns=['id', data_value_name, 'datetime'])\n",
    "\n",
    "        for fn_data in fn_data_li:\n",
    "            # read data\n",
    "            data_path = os.path.join(fd_day_path, fn_data)\n",
    "            data_df = read_traffic_speed(data_path)\n",
    "            # print('read data:', data_path)\n",
    "\n",
    "            if data_df is None:\n",
    "                continue \n",
    "\n",
    "            dt_str = fn_data.split('.')[0]\n",
    "            data_df['datetime'] = dt_str\n",
    "\n",
    "            # data_df['year']   = int(dt_str.split('-')[0])\n",
    "            # data_df['month']  = int(dt_str.split('-')[1])\n",
    "            # data_df['day']    = int(dt_str.split('-')[2])\n",
    "            # data_df['hour']   = int(dt_str.split('-')[3])\n",
    "            # data_df['minute'] = int(dt_str.split('-')[4])\n",
    "            # data_df['second'] = int(dt_str.split('-')[5])\n",
    "            data_day_df = pd.concat([data_day_df, data_df], ignore_index=True)\n",
    "\n",
    "        if data_day_df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        data_day_df = data_day_df.pivot(index='datetime', columns='id', values=data_value_name)\n",
    "        data_day_df.dropna(how='all', inplace=True)\n",
    "\n",
    "        dt_index = list(map(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d-%H-%M-%S\"),\n",
    "                            data_day_df.index.to_list()))\n",
    "\n",
    "        data_day_df.index = dt_index\n",
    "\n",
    "        # resample 1 hour (1H) mean\n",
    "        data_day_df = data_day_df.resample(rule='1H', closed='left', label='left').mean()\n",
    "        \n",
    "        # id list\n",
    "        id_li = data_day_df.columns.to_list()\n",
    "        \n",
    "        data_day_df['datetime'] = list(map(str, data_day_df.index))\n",
    "        data_day_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # one-day data\n",
    "        # data_oneday_df = pd.DataFrame(columns=['id', data_value_name, 'datetime'])\n",
    "        \n",
    "        for id_ in id_li:\n",
    "\n",
    "            data_day_df_id = data_day_df[[id_, 'datetime']].copy()\n",
    "            data_day_df_id['id'] = id_\n",
    "            data_day_df_id = data_day_df_id.rename(columns = {id_ : data_value_name})\n",
    "            # sort columns\n",
    "            data_day_df_id = data_day_df_id[['id', data_value_name, 'datetime']]\n",
    "            # data_oneday_df = pd.concat([data_oneday_df, data_day_df_id], ignore_index=True)\n",
    "            \n",
    "            # save one id data\n",
    "            if not (save_path is None):\n",
    "                # print('save: ', fn_data, id_)\n",
    "                data_day_df_id.to_csv(save_path, index=False, header=False,  mode='a')\n",
    "        \n",
    "        # data_month_df = pd.concat([data_month_df, data_oneday_df], ignore_index=True)\n",
    "        # # since the above processing is time-cosuming, \n",
    "        # # when one-day data is added, the file will be saved.\n",
    "        if not (save_path is None):\n",
    "            print('save: ', fn_data)\n",
    "        #     data_month_df.to_csv(save_path, index=False, header=False,  mode='a')\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af275f77-e701-47a9-852a-3b946661514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.path.join(os.getcwd(), '2022-06')\n",
    "data_value_name = 'speed'\n",
    "save_file = 'traffic_speed_data'\n",
    "\n",
    "load_one_month_data(root_folder, data_value_name, save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f31bf6-567b-44d1-b8a2-967d71aa1a77",
   "metadata": {},
   "source": [
    "### 2.2.2 Compute monthly average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c68a71-d341-43ce-a4af-e5760e3667c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one-month data\n",
    "data_month_df = pd.read_csv('carpark_data/carpark_1h_2022-06.csv',\n",
    "                            parse_dates = [2])\n",
    "\n",
    "data_month_df['hour'] = data_month_df['datetime'].dt.hour"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
