{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c8905d-0096-4532-a909-bd298555a417",
   "metadata": {},
   "source": [
    "\n",
    "**Carpark Availability data:** Request from Datamall API: 2.12 CARPARK AVAILABILITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817fcbd6-7429-49f0-9985-2bc10d195bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import zipfile\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00272da2-1e48-4d1a-8bd5-fd0e26fc5edd",
   "metadata": {},
   "source": [
    "# 1. Extract Carpark Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837a763-3e3a-4462-9614-d49c9b823ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_carpark_loc(path):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "        path : TYPE\n",
    "            DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "        data : TYPE\n",
    "            DESCRIPTION.\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    path = '2022-06/2022-06-01/2022-06-01-00-49-27.csv' \n",
    "    data = read_carpark_loc(path)\n",
    "\n",
    "    '''\n",
    "    # initialization\n",
    "    if path is None:\n",
    "        data = pd.DataFrame(columns = ['CarParkID', 'Development', 'LotType', 'Agency', 'id', 'lat', 'lng'],\n",
    "                            dtype = str)\n",
    "        return data\n",
    "    try:\n",
    "        if isinstance(path, str):\n",
    "            data = pd.read_csv(path, header=0, index_col=None, dtype=str)\n",
    "        elif isinstance(path, io.StringIO):\n",
    "            data = pd.read_csv(path, header=0, index_col=None, dtype=str)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # new carpark ID\n",
    "    data['id'] = data['CarParkID'].str.cat(data['LotType'].to_list(), sep='_')\n",
    "    \n",
    "    data['lat'] = data['Location'].str.split(' ').str.get(0)\n",
    "    data['lng'] = data['Location'].str.split(' ').str.get(1)\n",
    "    \n",
    "    data.drop(['Location', 'Area', 'AvailableLots'], axis=1, inplace=True)\n",
    "    \n",
    "    data = data.astype(dtype = str)\n",
    "    \n",
    "    return data\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a19d9e-9069-4478-a33d-6139738e26f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_carpark_loc_from_folder(folder_path, save_path=None):\n",
    "    '''\n",
    "    read one month carpark availability data, and extract the carpark location\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str) : DESCRIPTION.\n",
    "        save_path (str) : DESCRIPTION.\n",
    "\n",
    "    Returns:\n",
    "        data_month_df (pandas.DataFrame) : \n",
    "    \n",
    "    '''\n",
    "    # initialization\n",
    "    data_month_df = read_carpark_loc(path=None)\n",
    "    \n",
    "    fd_day_li = os.listdir(folder_path)\n",
    "    \n",
    "    for fdn in fd_day_li:\n",
    "        fd_day_path = os.path.join(folder_path, fdn)\n",
    "        fn_data_li = os.listdir(fd_day_path)\n",
    "        \n",
    "        for fn_data in fn_data_li:\n",
    "            \n",
    "            data_path = os.path.join(fd_day_path, fn_data)\n",
    "            data_new = read_carpark_loc(data_path)\n",
    "            \n",
    "            if data_new is None:\n",
    "                continue\n",
    "            \n",
    "            data_month_df = pd.concat([data_month_df, data_new], axis=0, ignore_index=True)\n",
    "            data_month_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "        \n",
    "        # drop duplicate\n",
    "        try:\n",
    "            assert data_month_df['id'].unique().shape[0] == data_month_df.shape[0]\n",
    "        except:\n",
    "            print('duplicate :', data_month_df['id'].unique().shape[0], data_month_df.shape[0])\n",
    "            data_month_df.drop_duplicates(subset=['id'], inplace=True)\n",
    "            \n",
    "    # save file\n",
    "    if not (save_path is None):\n",
    "        print('save: ', fdn, data_month_df.shape[0])\n",
    "        data_month_df.to_csv(save_path, index=False)\n",
    "    \n",
    "    return data_month_df\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1655fde-c953-497d-ac3c-36a97f2987e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_carpark_loc_from_zip(zip_path, save_path=None):\n",
    "    '''\n",
    "    read one month carpark availability data, and extract the carpark location\n",
    "\n",
    "    Parameters:\n",
    "        zip_path (str) : DESCRIPTION.\n",
    "        save_path (str) : DESCRIPTION.\n",
    "\n",
    "    Returns:\n",
    "        data_month_df (pandas.DataFrame) : \n",
    "    \n",
    "    '''\n",
    "    # initialization\n",
    "    data_month_df = read_carpark_loc(path=None)\n",
    "    \n",
    "    # read data (zip file)\n",
    "    zf = zipfile.ZipFile(zip_path)\n",
    "    file_path_li = zf.namelist()\n",
    "    \n",
    "    # file path dict\n",
    "    file_path_dict = {}\n",
    "    for file_path in file_path_li:\n",
    "        if not file_path.endswith('.csv'):\n",
    "            continue\n",
    "        file_dt = os.path.basename(file_path)[:10]\n",
    "        if file_dt in file_path_dict:\n",
    "            file_path_dict[file_dt].append(file_path)\n",
    "        else:\n",
    "            file_path_dict[file_dt] = [file_path]\n",
    "    \n",
    "    # every data file\n",
    "    for file_dt in sorted(file_path_dict.keys()):\n",
    "        print(\"Read file :\", file_dt)\n",
    "        for data_path in sorted(file_path_dict[file_dt]):\n",
    "            # print(file_dt, os.path.basename(data_path))\n",
    "            \n",
    "            data_str = io.StringIO(zf.read(data_path).decode('utf-8'))\n",
    "            data_new = read_carpark_loc(data_str)\n",
    "            \n",
    "            if data_new is None:\n",
    "                continue\n",
    "            \n",
    "            data_month_df = pd.concat([data_month_df, data_new], axis=0, ignore_index=True)\n",
    "            data_month_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "        \n",
    "        # drop duplicate\n",
    "        try:\n",
    "            assert data_month_df['id'].unique().shape[0] == data_month_df.shape[0]\n",
    "        except:\n",
    "            print('Duplicate :', data_month_df['id'].unique().shape[0], data_month_df.shape[0])\n",
    "            data_month_df.drop_duplicates(subset=['id'], inplace=True)\n",
    "    \n",
    "    # save file\n",
    "    if not (save_path is None):\n",
    "        print('Save: ', file_dt, data_month_df.shape[0])\n",
    "        data_month_df.to_csv(save_path, index=False)\n",
    "    \n",
    "    # close zipfile\n",
    "    zf.close()\n",
    "    \n",
    "    return data_month_df\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdff379-339f-44db-948d-9f122c1154e8",
   "metadata": {},
   "source": [
    "## 1.1 From Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147c706-0992-4172-b234-c520ad7c9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '2022-06/2022-06-01/2022-06-01-00-49-27.csv' \n",
    "data = read_carpark_loc(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f99c3-377c-4794-b7df-f1faf8fa6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the carpark location from one-month files\n",
    "\n",
    "folder_path = os.path.join(os.getcwd(), '2022-06')\n",
    "save_path = 'carpark_data/carpark_location_2022-06.csv'\n",
    "\n",
    "data = extract_carpark_loc_from_folder(folder_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12a7c6-a728-4894-b7e4-c4e56578f5ad",
   "metadata": {},
   "source": [
    "## 1.2 From Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106a6ff-7cc2-433b-9b98-996d381b62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the carpark location from one-month files\n",
    "zip_path = '2022-06.zip'\n",
    "save_path = 'carpark_data/carpark_location_2022-06.csv'\n",
    "data = extract_carpark_loc_from_zip(zip_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ab86e0-2061-478f-b9f4-8840cf72bf0b",
   "metadata": {},
   "source": [
    "# 2. Extract Carpark Availability Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972e69c-46ed-4c62-8017-7c220fb025f0",
   "metadata": {},
   "source": [
    "Load one-month data\n",
    "\n",
    "- **Resample frequency:** 1 hour\n",
    "\n",
    "- **Resample method:** average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5c665-e458-44a4-a197-c99353033f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_carpark_avali(path):\n",
    "    '''\n",
    "    \n",
    "    Parameters:\n",
    "        path (str) or : \n",
    "\n",
    "    Returns:\n",
    "        data (pandas.DataFrame) :\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        if isinstance(path, str):\n",
    "            data = pd.read_csv(path, header=0, index_col=None, dtype=str)\n",
    "        elif isinstance(path, io.StringIO):\n",
    "            data = pd.read_csv(path, header=0, index_col=None, dtype=str)\n",
    "    except:     # data is None\n",
    "        data = pd.DataFrame(columns=['id', 'lots'], dtype=str)\n",
    "        return None\n",
    "    \n",
    "    data['id'] = data['CarParkID'].str.cat(data['LotType'].to_list(), sep='_')\n",
    "    \n",
    "    data.drop_duplicates(inplace=True)\n",
    "    # print(data['id'].value_counts())\n",
    "    try:\n",
    "        assert data['id'].unique().shape[0] == data.shape[0]\n",
    "    except:\n",
    "        print('Unique Data Size: {0}. Data Size : {1}'.format(data['id'].unique().shape[0], \n",
    "                                                               data.shape[0]))\n",
    "        data.drop_duplicates(subset='id', inplace=True)\n",
    "    \n",
    "    # data.drop(['Location', 'Area', 'CarParkID', 'Development', 'LotType', 'Agency'], \n",
    "    #           axis=1, inplace=True)    \n",
    "    data = data.rename(columns = {'AvailableLots' : 'lots'})\n",
    "    data = data[['id', 'lots']]\n",
    "    data['lots'] = data['lots'].map(np.int32)\n",
    "\n",
    "    return data\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32033f0e-164c-47b0-889e-47187298f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_month_from_folder(root_folder, data_value_name, save_path=None):\n",
    "    # one-month data\n",
    "    data_month_df = pd.DataFrame(columns=['id', data_value_name, 'datetime'])\n",
    "    data_month_df.to_csv(save_path, index=False, header=True)\n",
    "    \n",
    "    # one month data\n",
    "    for fd_day in os.listdir(root_folder):\n",
    "\n",
    "        fd_day_path = os.path.join(root_folder, fd_day)\n",
    "        fn_data_li = os.listdir(fd_day_path)\n",
    "\n",
    "        # one day data\n",
    "        data_day_df = pd.DataFrame(columns=['id', data_value_name, 'datetime'])\n",
    "\n",
    "        for fn_data in fn_data_li:\n",
    "            # read data\n",
    "            data_path = os.path.join(fd_day_path, fn_data)\n",
    "            data_df = read_carpark_avali(data_path)\n",
    "            # print('read data:', data_path)\n",
    "\n",
    "            if data_df is None:\n",
    "                continue \n",
    "\n",
    "            dt_str = fn_data.split('.')[0]\n",
    "            data_df['datetime'] = dt_str\n",
    "\n",
    "            # data_df['year']   = int(dt_str.split('-')[0])\n",
    "            # data_df['month']  = int(dt_str.split('-')[1])\n",
    "            # data_df['day']    = int(dt_str.split('-')[2])\n",
    "            # data_df['hour']   = int(dt_str.split('-')[3])\n",
    "            # data_df['minute'] = int(dt_str.split('-')[4])\n",
    "            # data_df['second'] = int(dt_str.split('-')[5])\n",
    "            data_day_df = pd.concat([data_day_df, data_df], ignore_index=True)\n",
    "\n",
    "        if data_day_df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        data_day_df = data_day_df.pivot(index='datetime', columns='id', values=data_value_name)\n",
    "        data_day_df.dropna(how='all', inplace=True)\n",
    "\n",
    "        dt_index = list(map(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d-%H-%M-%S\"),\n",
    "                            data_day_df.index.to_list()))\n",
    "\n",
    "        data_day_df.index = dt_index\n",
    "\n",
    "        # resample 1 hour (1H) mean\n",
    "        data_day_df = data_day_df.resample(rule='1H', closed='left', label='left').mean()\n",
    "        \n",
    "        # id list\n",
    "        id_li = data_day_df.columns.to_list()\n",
    "        \n",
    "        data_day_df['datetime'] = list(map(str, data_day_df.index))\n",
    "        data_day_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # one-day data\n",
    "        # data_oneday_df = pd.DataFrame(columns=['id', data_value_name, 'datetime'])\n",
    "        \n",
    "        for id_ in id_li:\n",
    "\n",
    "            data_day_df_id = data_day_df[[id_, 'datetime']].copy()\n",
    "            data_day_df_id['id'] = id_\n",
    "            data_day_df_id = data_day_df_id.rename(columns = {id_ : data_value_name})\n",
    "            # sort columns\n",
    "            data_day_df_id = data_day_df_id[['id', data_value_name, 'datetime']]\n",
    "            # data_oneday_df = pd.concat([data_oneday_df, data_day_df_id], ignore_index=True)\n",
    "            \n",
    "            # save one id data\n",
    "            if not (save_path is None):\n",
    "                # print('save: ', fn_data, id_)\n",
    "                data_day_df_id.to_csv(save_path, index=False, header=False,  mode='a')\n",
    "        \n",
    "        # data_month_df = pd.concat([data_month_df, data_oneday_df], ignore_index=True)\n",
    "        # # since the above processing is time-cosuming, \n",
    "        # # when one-day data is added, the file will be saved.\n",
    "        if not (save_path is None):\n",
    "            print('save: ', fn_data)\n",
    "        #     data_month_df.to_csv(save_path, index=False, header=False,  mode='a')\n",
    "            \n",
    "    return None\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b5281-2d91-46db-bccb-66c91218f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_month_from_zip_file(zip_path, data_value_name, save_path=None):\n",
    "    '''\n",
    "    '''\n",
    "    # one-month data\n",
    "    df_header = ['id', data_value_name, 'datetime']\n",
    "    data_month_df = pd.DataFrame(columns=df_header)\n",
    "    # save header\n",
    "    data_month_df.to_csv(save_path, index=False, header=True)\n",
    "    \n",
    "    # read data (zip file)\n",
    "    zf = zipfile.ZipFile(zip_path)\n",
    "    file_path_li = zf.namelist()\n",
    "    \n",
    "    # file path dict\n",
    "    file_path_dict = {}\n",
    "    for file_path in file_path_li:\n",
    "        if not file_path.endswith('.csv'):\n",
    "            continue\n",
    "        file_dt = os.path.basename(file_path)[:10]\n",
    "        if file_dt in file_path_dict:\n",
    "            file_path_dict[file_dt].append(file_path)\n",
    "        else:\n",
    "            file_path_dict[file_dt] = [file_path]\n",
    "    \n",
    "    # every data file\n",
    "    for file_dt in sorted(file_path_dict.keys()):\n",
    "        print(\"Read File :\", file_dt)\n",
    "\n",
    "        # one day data\n",
    "        data_day_df = []\n",
    "        for data_path in sorted(file_path_dict[file_dt]):\n",
    "            # print(os.path.basename(file_path))\n",
    "        \n",
    "            # read data\n",
    "            data_str = io.StringIO(zf.read(data_path).decode('utf-8'))\n",
    "            data_df = read_carpark_avali(data_str)\n",
    "            # print('read data:', data_path)\n",
    "            \n",
    "            if data_df is None:\n",
    "                continue \n",
    "            \n",
    "            data_df['datetime'] = os.path.basename(data_path).split(\".\")[0]\n",
    "            \n",
    "            # data_df['year']   = int(dt_str.split('-')[0])\n",
    "            # data_df['month']  = int(dt_str.split('-')[1])\n",
    "            # data_df['day']    = int(dt_str.split('-')[2])\n",
    "            # data_df['hour']   = int(dt_str.split('-')[3])\n",
    "            # data_df['minute'] = int(dt_str.split('-')[4])\n",
    "            # data_df['second'] = int(dt_str.split('-')[5])\n",
    "            data_day_df.append(data_df)\n",
    "        \n",
    "        if len(data_day_df) == 0:\n",
    "            continue\n",
    "\n",
    "        # one-day data\n",
    "        data_day_df = pd.concat(data_day_df, ignore_index=True)\n",
    "\n",
    "        data_day_df = data_day_df.pivot(index='datetime', columns='id', values=data_value_name)\n",
    "        data_day_df.dropna(how='all', axis=0, inplace=True)\n",
    "\n",
    "        # parse datetime\n",
    "        dt_index = list(map(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d-%H-%M-%S\"),\n",
    "                            data_day_df.index.to_list()))\n",
    "        \n",
    "        data_day_df.index = dt_index\n",
    "\n",
    "        # resample 1 hour (1H) mean\n",
    "        data_day_df = data_day_df.resample(rule='1H', closed='left', label='left').mean()\n",
    "        \n",
    "        # id list\n",
    "        id_li = data_day_df.columns.to_list()\n",
    "        \n",
    "        data_day_df['datetime'] = list(map(str, data_day_df.index.to_list()))\n",
    "        data_day_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        data_df_ = data_day_df.melt(id_vars=['datetime'], value_vars=id_li,\n",
    "                                    var_name='id', value_name=data_value_name)\n",
    "        data_df_ = data_df_[df_header]\n",
    "        \n",
    "        # save one id data\n",
    "        if not (save_path is None):\n",
    "            print('Save: ', file_dt, time.ctime())\n",
    "            data_df_.to_csv(save_path, index=False, header=False,  mode='a')\n",
    "    \n",
    "    # close zipfile\n",
    "    zf.close()\n",
    "    \n",
    "    return None\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031a834-65f3-47d7-9369-be9b7d6b3578",
   "metadata": {},
   "source": [
    "## 2.1 From Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444c3fe-da5c-4860-9373-e93d5f564d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.path.join(os.getcwd(), '2022-06')\n",
    "data_value_name = 'lots'\n",
    "save_path = 'carpark_data/carpark_1h_2022-06.csv'\n",
    "\n",
    "load_one_month_from_folder(root_folder, data_value_name, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e38442-7719-4c94-a117-8690391ec72e",
   "metadata": {},
   "source": [
    "## 2.2 From Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274b774-e221-4488-83f9-7087e2615fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = '2022-06.zip'\n",
    "data_value_name = 'lots'\n",
    "save_path = 'carpark_data/carpark_1h_2022-06.csv'\n",
    "\n",
    "load_one_month_from_zip_file(zip_path, data_value_name, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e823ee-c38c-42f1-a6bc-1f03c461344e",
   "metadata": {},
   "source": [
    "# 3. Compute Monthly Average Data\n",
    "\n",
    "- Weekday Average\n",
    "\n",
    "- Weekends Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499f610-e187-45b4-8f58-4ea9b298621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one-month data\n",
    "file_path = 'carpark_data/carpark_1h_2022-06.csv'\n",
    "data_month_df = pd.read_csv(file_path, parse_dates=[2])\n",
    "\n",
    "data_month_df['hour'] = data_month_df['datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae299951-6c3d-4532-95de-aac8ae810afa",
   "metadata": {},
   "source": [
    "weekday and weekends/holiday information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6f048-5118-455e-8d08-3d9a4359eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'is_weekday' column to indicate \n",
    "data_month_df['is_weekday'] = data_month_df['datetime'].dt.dayofweek\n",
    "data_month_df['is_weekday'] = data_month_df['is_weekday'].apply(lambda x: True if x <= 4 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c559bc-88e4-4550-8fc3-0612facb1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_month_df.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "# x = data_month_df[data_month_df['is_weekday'] == False]\n",
    "# x['day'] = data_month_df['datetime'].dt.day\n",
    "# x = x.drop_duplicates(subset=['day', 'is_weekday'])\n",
    "\n",
    "data_month_df = data_month_df.groupby(['id', 'hour', 'is_weekday'], as_index=False).mean()\n",
    "\n",
    "save_path = 'carpark_data/carpark_1h_mean_2022-06.csv'\n",
    "data_month_df.to_csv(save_path, index=False)\n",
    "# data_all_df1.plot(lw=1, alpha=0.5, color='skyblue', legend=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
